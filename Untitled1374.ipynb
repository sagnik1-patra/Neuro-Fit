{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "726eb889-c4d3-408c-a517-bc7ffcf163c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- put this right after: bundle = safe_load_bundle(PKL_PATH) ---\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import re\n",
    "\n",
    "preprocess = bundle[\"preprocess\"]\n",
    "datetime_cols_cfg = bundle.get(\"datetime_cols\", None)\n",
    "\n",
    "# 1) recursively patch DateTimeExpand instances inside preprocess\n",
    "def _walk_and_patch(est):\n",
    "    # DateTimeExpand from our shim\n",
    "    if est.__class__.__name__ == \"DateTimeExpand\":\n",
    "        # ensure features list exists and uses single-underscore naming internally\n",
    "        if not hasattr(est, \"features\") or est.features is None:\n",
    "            est.features = [\"year\", \"month\", \"day\", \"dow\", \"hour\"]\n",
    "        # if no cols set in the pickled object, use bundle's datetime_cols\n",
    "        if (not hasattr(est, \"cols\") or est.cols is None or len(est.cols)==0) and datetime_cols_cfg:\n",
    "            est.cols = list(datetime_cols_cfg)\n",
    "        # make sure we don't accidentally keep originals if the trained pipe dropped them\n",
    "        if not hasattr(est, \"drop_original\"):\n",
    "            est.drop_original = False\n",
    "        return\n",
    "\n",
    "    # sklearn containers\n",
    "    if isinstance(est, Pipeline):\n",
    "        for name, step in est.steps:\n",
    "            _walk_and_patch(step)\n",
    "    elif isinstance(est, ColumnTransformer):\n",
    "        for name, trans, cols in est.transformers_:\n",
    "            _walk_and_patch(trans)\n",
    "\n",
    "_walk_and_patch(preprocess)\n",
    "\n",
    "\n",
    "# 2) A sanitizer to fix any double-underscore datetime columns in the *input* df\n",
    "_dt_part = r\"(year|month|day|dow|hour)\"\n",
    "_double_dt_re = re.compile(rf\"^(.*)__{_dt_part}$\")\n",
    "\n",
    "def sanitize_datetime_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        df = pd.DataFrame(df)\n",
    "    rename_map = {}\n",
    "    drop_cols  = []\n",
    "    for c in list(df.columns):\n",
    "        m = _double_dt_re.match(c)\n",
    "        if m:\n",
    "            base, part = m.group(1), m.group(2)\n",
    "            fixed = f\"{base}_{part}\"\n",
    "            # if the fixed name already exists, drop the double-underscore version\n",
    "            if fixed in df.columns:\n",
    "                drop_cols.append(c)\n",
    "            else:\n",
    "                rename_map[c] = fixed\n",
    "    if rename_map:\n",
    "        df = df.rename(columns=rename_map)\n",
    "    if drop_cols:\n",
    "        df = df.drop(columns=drop_cols)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7599182-b0ae-4b29-8018-810f4922c219",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (moviepy)",
   "language": "python",
   "name": "py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
